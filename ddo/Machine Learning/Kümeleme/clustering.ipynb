{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fa1648e-28e6-4705-a8e9-83c623db4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from typing import List\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans , AgglomerativeClustering\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "#from matpoltlib import pyplot as plotter\n",
    "\n",
    "#shift + enter : to run the cell (choose the one first)\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6b0a7ad-7368-482f-b1c4-2edcee26d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniform_dataset(n_data_points = 100,\n",
    "                             feature_range: int = 1.0,\n",
    "                             random_state: int = None):\n",
    "    if random_state is None :\n",
    "        random_state = int(random.random() * 100)\n",
    "    return numpy.random.RandomState(random_state).uniform(0,\n",
    "                                                          feature_range,\n",
    "                                                          size=(n_data_points, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7b5ef2c-5083-4000-bdb2-961d67d55165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blobbed_dataset(n_data_points=100,\n",
    "                             feature_range: int= 1.0,\n",
    "                             n_blobs : int = 3,\n",
    "                             blob_std: float = None,\n",
    "                             blob_centers: List[List[float]] = None,\n",
    "                             size_blobs: List[int] = None,\n",
    "                             random_state: int = None):\n",
    "    if random_state is None :\n",
    "        random_state = int(random.random() * 100)\n",
    "    if blob_std is None :\n",
    "        random.random()* 0.2 * feature_range\n",
    "    if blob_centers is None :\n",
    "        blob_centers = [[random.random() * feature_range,\n",
    "                         random.random() * feature_range] for x in range(n_blobs)]\n",
    "    if size_blobs is None :\n",
    "        size_blobs = [int(random.random() * 10) for x in range(n_blobs)]\n",
    "\n",
    "    blob_samples = []\n",
    "\n",
    "    for blob_counter in range(len(size_blobs)):\n",
    "        blob_samples.append(n_data_points * size_blobs[blob_counter] // sum(size_blobs))\n",
    "    return make_blobs(n_samples=blob_samples,\n",
    "                      cluster_std=blob_std,\n",
    "                      centers=blob_centers,\n",
    "                      random_state=random_state)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a60e073-55e5-46ea-b701-5b6c783b3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data\n",
    "data_points = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "651742fa-3aee-4eb9-a18f-b1a1b48cca0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniform_dataset = DataFrame(data = generate_uniform_dataset(data_points),\n",
    "                            columns = ['X','Y'])\n",
    "blobbed_dataset = DataFrame(data = generate_blobbed_dataset(n_data_points = data_points,\n",
    "                                                            n_blobs = 4,\n",
    "                                                            blob_std = 0.1,\n",
    "                                                            blob_centers = [[0.7, 0.2],\n",
    "                                                                            [0.2, 0.1],\n",
    "                                                                            [0.3, 0.8],\n",
    "                                                                            [0.9, 0.9]],\n",
    "                                                            size_blobs = [2,\n",
    "                                                                      3,\n",
    "                                                                      5,\n",
    "                                                                      7]),\n",
    "                            columns = ['X','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd63128d-ae40-409b-984d-6612ac914dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            X         Y\n",
      "0    0.517298  0.946963\n",
      "1    0.765460  0.282396\n",
      "2    0.221045  0.686222\n",
      "3    0.167139  0.392442\n",
      "4    0.618052  0.411930\n",
      "..        ...       ...\n",
      "195  0.705562  0.759282\n",
      "196  0.272440  0.465636\n",
      "197  0.724480  0.082832\n",
      "198  0.849127  0.720649\n",
      "199  0.990482  0.445845\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(uniform_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0762297-7b00-4865-a82e-785413863bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            X         Y\n",
      "0    0.845378  0.938488\n",
      "1    0.690015  0.218428\n",
      "2    0.801675  0.156953\n",
      "3    0.207651  0.761434\n",
      "4    0.870298  0.843116\n",
      "..        ...       ...\n",
      "193  0.250493  0.099098\n",
      "194  0.891615  1.013480\n",
      "195  0.227355  0.222535\n",
      "196  0.423271  0.752829\n",
      "197  0.354668  0.649857\n",
      "\n",
      "[198 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(blobbed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f84a8192-fd9e-45db-baec-0e78a5df75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_cluster = 2\n",
    "data_in = blobbed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c124090e-e98b-45c8-ae71-9c8819267b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert kmeans, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33556\\798549166.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclust_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4927\u001b[0m                 \u001b[1;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4928\u001b[0m             )\n\u001b[0;32m   4929\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4930\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4931\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4932\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4933\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loc must be int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4934\u001b[0m         \u001b[1;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert kmeans, already exists"
     ]
    }
   ],
   "source": [
    "model_kmeans = KMeans(number_of_cluster) \n",
    "model_kmeans.fit(data_in)\n",
    "clust_labels = model_kmeans.predict(data_in)\n",
    "cent = model_kmeans.cluster_centers_\n",
    "kmeans = DataFrame(clust_labels)\n",
    "data_in.insert((data_in.shape[1]), 'kmeans', kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6651ee-7836-487b-a508-a7ec3097a04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
